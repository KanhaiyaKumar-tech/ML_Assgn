{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7514a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037699f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. What is the definition of a target function? In the sense of a real-life example, express the target\n",
    "function. How is a target function&#39;s fitness assessed?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975f0f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "Target function is the function that a machine learning model aims to approximate or learn from the available data. It represents the mapping between the input variables (features) and the output variable (target) that the model tries to predict. In a real-life example, the target function could be predicting house prices based on features like the number of bedrooms, square footage, and location. The fitness of a target function is assessed by measuring how well it can predict or approximate the target variable based on the input features. This is typically evaluated using evaluation metrics such as accuracy, mean squared error, or area under the curve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbea145",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fb2d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. What are predictive models, and how do they work? What are descriptive types, and how do you\n",
    "use them? Examples of both types of models should be provided. Distinguish between these two\n",
    "forms of models.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac2a2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictive models are machine learning models that are designed to make predictions or estimates about future or unseen data based on patterns observed in the training data. They learn from historical data to identify relationships and patterns that can be used to predict the target variable. Examples of predictive models include linear regression, decision trees, and neural networks. Descriptive models, on the other hand, aim to describe or summarize the existing data without making predictions. They focus on understanding the patterns, relationships, and characteristics of the data. Examples of descriptive models include clustering algorithms, association rules, and dimensionality reduction techniques. The main difference between predictive and descriptive models lies in their purpose and usage.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0196ad93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1a94ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. Describe the method of assessing a classification model&#39;s efficiency in detail. Describe the various\n",
    "measurement parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55ac3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "The efficiency of a classification model can be assessed using various evaluation metrics:\n",
    "\n",
    "- Accuracy: The proportion of correctly classified instances to the total number of instances.\n",
    "\n",
    "- Confusion Matrix: A table that presents the predicted and actual class labels, allowing the calculation of metrics such as true positive (TP), true negative (TN), false positive (FP), and false negative (FN).\n",
    "\n",
    "- Precision: The proportion of true positives (correctly predicted positives) to the sum of true positives and false positives.\n",
    "\n",
    "- Recall (Sensitivity): The proportion of true positives to the sum of true positives and false negatives.\n",
    "\n",
    "- F1-Score: The harmonic mean of precision and recall, providing a balanced measure of model performance.\n",
    "\n",
    "- Area Under the ROC Curve (AUC-ROC): The measure of the model's ability to discriminate between positive and negative classes, based on the receiver operating characteristic curve.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084f57bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b745fd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "4.\n",
    "i. In the sense of machine learning models, what is underfitting? What is the most common\n",
    "reason for underfitting?\n",
    "ii. What does it mean to overfit? When is it going to happen?\n",
    "iii. In the sense of model fitting, explain the bias-variance trade-off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20af0efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "   i. Underfitting occurs when a machine learning model is too simple or lacks complexity to capture the underlying patterns in the data. It leads to poor performance on both training and test data. The most common reason for underfitting is when the model has insufficient complexity or is not trained with enough data.\n",
    "\n",
    "   ii. Overfitting occurs when a machine learning model is overly complex or closely fits the training data, capturing noise or random fluctuations. It leads to low bias but high variance, resulting in poor generalization to unseen data. Overfitting often happens when the model is too complex relative to the available training data or when the model is trained for too long, memorizing the training examples.\n",
    "\n",
    "   iii. The bias-variance trade-off is a fundamental concept in model fitting. Bias refers to the error introduced by approximating a real-world problem with a simplified model. High bias can lead to underfitting. Variance refers to the model's sensitivity to small fluctuations or noise in the training data. High variance can lead to overfitting. The trade-off involves finding the right balance between bias and variance to achieve optimal model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ff6c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb087c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. Is it possible to boost the efficiency of a learning model? If so, please clarify how.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880e1b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "Yes, the efficiency of a learning model can be boosted using various techniques:\n",
    "\n",
    "- Feature Engineering: Creating or selecting informative features from the available data can significantly improve model performance.\n",
    "\n",
    "- Hyperparameter Tuning: Optimizing the hyperparameters of a model can enhance its performance by finding the best configuration for the specific problem.\n",
    "\n",
    "- Ensemble Methods: Combining multiple models through techniques like bagging, boosting, or stacking can improve predictive performance and increase robustness.\n",
    "\n",
    "- Regularization: Applying regularization techniques such as L1 or L2 regularization can help prevent overfitting and improve generalization.\n",
    "\n",
    "- Data Augmentation: Increasing the size or diversity of the training data through techniques like data synthesis or augmentation can improve the model's ability to generalize.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6301367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8fe0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. How would you rate an unsupervised learning model&#39;s success? What are the most common\n",
    "success indicators for an unsupervised learning model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4121e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "The success of an unsupervised learning model is typically measured using evaluation metrics such as:\n",
    "\n",
    "- Silhouette Score: A measure of cluster quality that considers both the cohesion of points within clusters and the separation between different clusters. Higher silhouette scores indicate better-defined and distinct clusters.\n",
    "\n",
    "- Cluster Separation: Assessing the extent to which different clusters are well-separated and distinct from each other.\n",
    "\n",
    "- Cluster Compactness: Evaluating how closely related points within each cluster are to each other, measuring the tightness or compactness of the clusters.\n",
    "\n",
    "- Visualization: Visual inspection of the clustered data can provide insights into the quality and meaningfulness of the clustering results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75036f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390a55a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. Is it possible to use a classification model for numerical data or a regression model for categorical\n",
    "data with a classification model? Explain your answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245d7af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Classification models are designed to predict categorical labels or classes based on input features, while regression models are used to predict continuous numerical values. Therefore, it is not appropriate to use a classification model for numerical data or a regression model for categorical data. The choice of the model depends on the nature of the target variable and the task at hand.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35448a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6dfc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "8. Describe the predictive modeling method for numerical values. What distinguishes it from\n",
    "categorical predictive modeling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437d7f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictive modeling for numerical values involves using regression models to predict continuous numerical outcomes. These models estimate the relationship between input variables and the target variable, allowing predictions of numerical values. Categorical predictive modeling, on the other hand, involves using classification models to assign instances to predefined categories or labels based on input features. The main distinction is in the type of output variable the models aim to predict.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ff3b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e69ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "9. The following data were collected when using a classification model to predict the malignancy of a\n",
    "group of patients&#39; tumors:\n",
    "i. Accurate estimates – 15 cancerous, 75 benign\n",
    "ii. Wrong predictions – 3 cancerous, 7 benign\n",
    "Determine the model&#39;s error rate, Kappa value, sensitivity, precision, and F-measure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea3274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Given the data:\n",
    "\n",
    "i. Accurate estimates: 15 cancerous, 75 benign\n",
    "ii. Wrong predictions: 3 cancerous, 7 benign\n",
    "\n",
    "- Error Rate: (False Positives + False Negatives) / Total instances = (\n",
    "\n",
    "3 + 7) / (15 + 75) = 0.1 or 10%\n",
    "- Kappa Value: Calculated using the observed accuracy and the expected accuracy by chance, providing a measure of agreement beyond chance.\n",
    "- Sensitivity (Recall): True Positives / (True Positives + False Negatives) = 15 / (15 + 3) = 0.8333 or 83.33%\n",
    "- Precision: True Positives / (True Positives + False Positives) = 15 / (15 + 7) = 0.6818 or 68.18%\n",
    "- F-measure: Harmonic mean of precision and recall, combining their performance into a single metric.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03139c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95414b64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6278e547",
   "metadata": {},
   "outputs": [],
   "source": [
    "10. Make quick notes on:\n",
    "1. The process of holding out\n",
    "2. Cross-validation by tenfold\n",
    "3. Adjusting the parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b84fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Quick notes:\n",
    "\n",
    "- The process of holding out: Refers to reserving a portion of the available data as a separate hold-out or validation set, which is not used during model training but rather for evaluating the model's performance on unseen data.\n",
    "\n",
    "- Cross-validation by tenfold: A technique where the data is divided into ten equal-sized folds, with each fold serving as a validation set once while the remaining nine folds are used for training. It helps estimate the model's performance and assess its generalization ability.\n",
    "\n",
    "- Adjusting the parameters: Involves tuning the hyperparameters or settings of a model to find the optimal configuration for a specific problem. This is done based on the evaluation of model performance using validation data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301f6dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34da23e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0530c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45d34ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "11. Define the following terms:\n",
    "1. Purity vs. Silhouette width\n",
    "2. Boosting vs. Bagging\n",
    "3. The eager learner vs. the lazy learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add23202",
   "metadata": {},
   "outputs": [],
   "source": [
    " Definitions:\n",
    "\n",
    "- Purity vs. Silhouette width:\n",
    "  - Purity is a measure used in clustering to assess the quality of cluster assignments. It evaluates how well instances within each cluster belong to the same class or category.\n",
    "  - Silhouette width is a measure used to evaluate the quality of clustering results. It considers both the cohesion within clusters and the separation between different clusters.\n",
    "\n",
    "- Boosting vs. Bagging:\n",
    "  - Boosting is an ensemble method that combines multiple weak models sequentially, with each model focusing on the instances that were previously misclassified. It aims to improve the overall model's performance by giving more weight to difficult instances.\n",
    "  - Bagging is an ensemble method that combines multiple models independently, with each model trained on a random subset of the data with replacement. It aims to reduce the variance and increase stability by averaging the predictions of multiple models.\n",
    "\n",
    "- Eager learner vs. Lazy learner:\n",
    "  - Eager learners, also known as eager learning algorithms, eagerly build a model based on the entire training dataset during the learning phase. The model is then used to make predictions on new instances.\n",
    "  - Lazy learners, also known as lazy learning algorithms, delay the learning process until a new instance needs to be classified. They store the training instances and use them directly during classification, without creating a general model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057f8cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ea67b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f934e22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb87e77c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5a1f53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea095b84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef8b717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79e3563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee30251b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93609b19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3bab71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb4e4f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd00eadd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5480164d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d67ee59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c053a60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ad4eaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cacbe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c92ce25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeaba90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db117771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717f0b86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697004a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa584e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4257df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5d60f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee49215e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d65dcbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61898f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
